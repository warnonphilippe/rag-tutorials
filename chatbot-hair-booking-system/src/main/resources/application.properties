### LangChain4J Configuration for Antrhopic Chat Model
#langchain4j.anthropic.chat-model.api-key=${CLAUDE_API_KEY}
#langchain4j.anthropic.chat-model.model-name=claude-3-5-sonnet-20241022
#langchain4j.anthropic.chat-model.strict-tools=true
#langchain4j.anthropic.chat-model.temperature=0.0
#langchain4j.anthropic.chat-model.timeout=PT60S
#langchain4j.anthropic.chat-model.log-requests=false
#langchain4j.anthropic.chat-model.log-responses=false

### LangChain4J Configuration for OpenAI Chat Model
langchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}
langchain4j.open-ai.chat-model.strict-tools=true
langchain4j.open-ai.chat-model.model-name=gpt-4o 
langchain4j.open-ai.chat-model.temperature=0.0
langchain4j.open-ai.chat-model.timeout=PT60S
langchain4j.open-ai.chat-model.log-requests=false
langchain4j.open-ai.chat-model.log-responses=false

### LangChain4J Configuration for Ollama and DeepSeek R1 Chat Model
#langchain4j.ollama.chat-model.base-url=http://localhost:11434
#langchain4j.ollama.chat-model.model-name=deepseek-r1
#langchain4j.ollama.chat-model.strict-tools=true
#langchain4j.ollama.chat-model.model-name=gpt-4o 
#langchain4j.ollama.chat-model.temperature=0.0
#langchain4j.ollama.chat-model.timeout=PT60S
#langchain4j.ollama.chat-model.log-requests=false
#langchain4j.ollama.chat-model.log-responses=false

logging.level.org.springframework=ERROR
logging.level.dev.langchain4j=DEBUG
logging.level.ai.djl=DEBUG

spring.datasource.driverClassName=org.h2.Driver
spring.datasource.url=jdbc:h2:mem:hair_booking
spring.h2.console.enabled=true
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.jpa.hibernate.ddl-auto=create
spring.jpa.show-sql=false